import requests
from bs4 import BeautifulSoup
import webbrowser
import time
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.common.exceptions import NoSuchElementException
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

BASE_URL = 'https://blood-records.co.uk'
TARGET_URL = f"{BASE_URL}/collections/all"
KEYWORDS = ["kae", "chappell", "gaga", "ariana", "taylor", "gracie"]
EXCLUDE = ['sabrinacarpenter']

def is_excluded(text: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦å‘½ä¸­æ’é™¤é¡¹ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰"""
    return any(ex.lower() in text.lower() for ex in EXCLUDE)

def find_matching_product():
    resp = requests.get(TARGET_URL, headers={"User-Agent": "Mozilla/5.0"})
    soup = BeautifulSoup(resp.text, "html.parser")

    slides = soup.select("div.slideshow__slide a")
    for slide in slides:
        href = slide.get("href", "")
        full_url = BASE_URL + href
        lower_href = href.lower()

        for kw in KEYWORDS:
            if kw.lower() in lower_href and not is_excluded(lower_href):
                print(f"ğŸ¯ å‘ç°åŒ¹é…å•†å“ï¼š{full_url}")
                check_add_to_cart(full_url)
                return full_url

    print("âŒ æ²¡æœ‰æ‰¾åˆ°åŒ¹é…å•†å“")
    return None

def check_add_to_cart(url):
    # æ›¿æ¢ä¸ºä½ è‡ªå·±çš„ç”¨æˆ·åï¼ˆæˆ–ç”¨ç¯å¢ƒå˜é‡ä¹Ÿå¯ä»¥ï¼‰
    options = Options()
    options.add_argument(r"--user-data-dir=C:\Users\admin\AppData\Local\Google\Chrome\User Data")
    options.add_argument("--profile-directory=Default")  # å¯æ”¹ä¸º"Profile 1"ç­‰
    options.add_argument("--start-maximized")
    options.add_experimental_option("excludeSwitches", ["enable-automation"])

    driver = webdriver.Chrome(options=options)
    driver.get(url)

    try:
        # ç­‰å¾…å¹¶ç‚¹å‡» "Add to cart"
        add_btn = WebDriverWait(driver, 10).until(
            EC.element_to_be_clickable((By.XPATH, "//button[contains(text(), 'Add to cart')]"))
        )
        print("ğŸ›’ åŠ å…¥è´­ç‰©è½¦æŒ‰é’®å·²æ‰¾åˆ°ï¼Œç‚¹å‡»ä¸­...")
        add_btn.click()

        # ç­‰å¾…è·³è½¬å¹¶å‡ºç° "CHECKOUT" æŒ‰é’®
        checkout_btn = WebDriverWait(driver, 15).until(
            EC.element_to_be_clickable((By.XPATH, "//button[@name='checkout' and contains(text(), 'CHECKOUT')]"))
        )
        print("ğŸ’³ ç»“è´¦æŒ‰é’®å·²å‡ºç°ï¼Œç‚¹å‡»ä¸­...")
        checkout_btn.click()

    except Exception as e:
        print(f"âŒ æ“ä½œå¤±è´¥: {e}")
    # driver.quit()

def print_matching_products():
    resp = requests.get(TARGET_URL, headers={"User-Agent": "Mozilla/5.0"})
    soup = BeautifulSoup(resp.text, "html.parser")

    slides = soup.select("div.slideshow__slide a")

    found = False
    for slide in slides:
        href = slide.get("href", "")
        full_url = BASE_URL + href
        lower_href = href.lower()

        img = slide.find("img")
        title_guess = ""
        if img:
            if img.get("alt"):
                title_guess = img["alt"]
            elif img.get("data-src"):
                title_guess = img["data-src"].split("/")[-1].split(".")[0]
            elif img.get("src"):
                title_guess = img["src"].split("/")[-1].split(".")[0]

        lower_title = title_guess.lower()

        for kw in KEYWORDS:
            if (kw.lower() in lower_href or kw.lower() in lower_title) and not (
                is_excluded(lower_href) or is_excluded(lower_title)
            ):
                print(f"ğŸ¯ æ‰¾åˆ°åŒ¹é…å•†å“ï¼š{title_guess} - {full_url}")
                found = True

    if not found:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°åŒ¹é…å•†å“")

def monitor(interval=10):
    print("å¼€å§‹ç›‘æ§ Blood Records æ–°å“...")
    last_hit = None
    while True:
        try:
            result = find_matching_product()
            if result and result != last_hit:
                last_hit = result
        except Exception as e:
            print(f'å‘ç”Ÿé”™è¯¯ï¼š{e}')
        time.sleep(interval)